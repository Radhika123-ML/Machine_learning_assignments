{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. Provide an example of the concepts of Prior, Posterior, and\n",
    "Likelihood.**\n",
    "\n",
    "we have a group of 100 people, and we want to determine the probability\n",
    "that a randomly chosen person from this group is a basketball player.\n",
    "**We can denote the following:**\n",
    "\n",
    "**Prior:** The prior probability is our initial belief or assumption\n",
    "about the probability of someone being a basketball player before\n",
    "considering any new information. Let's say our prior belief is that 20%\n",
    "of the people in the group are basketball players. This is our prior\n",
    "probability.\n",
    "\n",
    "**Posterior:** The posterior probability is the updated probability\n",
    "after taking into account new evidence or information. Let's say we\n",
    "gather additional information and find out that 30 people in the group\n",
    "are basketball players. Based on this new information, we can calculate\n",
    "the posterior probability, which represents the probability of someone\n",
    "being a basketball player given the new evidence.\n",
    "\n",
    "**Likelihood:** The likelihood is the probability of observing the\n",
    "evidence given a particular hypothesis or belief. In this case, it\n",
    "represents the probability of seeing 30 basketball players in a group of\n",
    "100 people, given that our prior belief was that 20% of the people are\n",
    "basketball players.\n",
    "\n",
    "**To summarize:**\n",
    "\n",
    "Prior probability: We assume that 20% of the people in the group are\n",
    "basketball players.\n",
    "\n",
    "**Likelihood:** The probability of observing 30 basketball players in a\n",
    "group of 100 people, given our prior assumption of 20% basketball\n",
    "players.\n",
    "\n",
    "**Posterior probability:** The updated probability of someone being a\n",
    "basketball player after considering the new evidence of 30 basketball\n",
    "players in the group.\n",
    "\n",
    "**Q2. What role does Bayes' theorem play in the concept learning\n",
    "principle?**\n",
    "\n",
    "Bayes' theorem is a fundamental principle in probability theory and\n",
    "statistics that plays a crucial role in the concept learning principle.\n",
    "The concept learning principle aims to update our beliefs or knowledge\n",
    "about a concept based on new evidence or information.\n",
    "\n",
    "Bayes' theorem provides a formal framework for updating probabilities\n",
    "based on new evidence. It allows us to calculate the posterior\n",
    "probability of a hypothesis or belief given the prior probability and\n",
    "the likelihood of observing the evidence.\n",
    "\n",
    "In the context of concept learning, Bayes' theorem helps us update our\n",
    "prior beliefs or hypotheses about a concept based on observed data or\n",
    "examples. It enables us to calculate the posterior probability of a\n",
    "hypothesis or concept being true, given the prior probability and the\n",
    "likelihood of observing the data.\n",
    "\n",
    "By iteratively applying Bayes' theorem and updating our beliefs based on\n",
    "new evidence, we can refine our understanding of a concept and improve\n",
    "our predictions or inferences. This iterative process of updating\n",
    "beliefs using Bayes' theorem is often referred to as Bayesian inference.\n",
    "\n",
    "In summary, Bayes' theorem is a key principle in concept learning as it\n",
    "provides a formal and systematic way to update and refine our beliefs\n",
    "about a concept based on new evidence, leading to more accurate and\n",
    "informed understanding of the concept.\n",
    "\n",
    "**Q3. Offer an example of how the Nave Bayes classifier is used in real\n",
    "life.**\n",
    "\n",
    "One common application of the Naive Bayes classifier in real life is\n",
    "spam email filtering. Spam email filtering is a task where we want to\n",
    "classify incoming emails as either spam or non-spam (also known as ham).\n",
    "The Naive Bayes classifier is a popular choice for this task due to its\n",
    "simplicity and effectiveness.\n",
    "\n",
    "Here's how the Naive Bayes classifier can be used for spam email\n",
    "filtering:\n",
    "\n",
    "1\\. Data collection: A large dataset of emails is collected, consisting\n",
    "of both spam and non-spam emails. Each email is labeled as either spam\n",
    "or non-spam.\n",
    "\n",
    "2\\. Feature extraction: Relevant features are extracted from the emails,\n",
    "such as the presence or absence of certain words, the frequency of\n",
    "certain words, or other characteristics that can help distinguish\n",
    "between spam and non-spam emails.\n",
    "\n",
    "3\\. Training: The Naive Bayes classifier is trained using the labeled\n",
    "dataset. It estimates the prior probabilities of spam and non-spam\n",
    "emails and calculates the likelihood of observing the extracted features\n",
    "given the class labels (spam or non-spam).\n",
    "\n",
    "4\\. Classification: When a new email arrives, the Naive Bayes classifier\n",
    "applies Bayes' theorem to calculate the posterior probability of the\n",
    "email being spam or non-spam, based on the observed features. The email\n",
    "is then classified as spam or non-spam based on the higher posterior\n",
    "probability.\n",
    "\n",
    "5\\. Iterative learning: As new emails are classified, the classifier can\n",
    "be continuously updated by incorporating the new data into the training\n",
    "set. This iterative learning process helps improve the classifier's\n",
    "accuracy over time.\n",
    "\n",
    "By leveraging the probabilistic framework of Bayes' theorem and assuming\n",
    "independence between features (hence the \"naive\" assumption), the Naive\n",
    "Bayes classifier provides a fast and efficient way to classify emails as\n",
    "spam or non-spam. It has been widely adopted in various email systems\n",
    "and spam filtering services to protect users from unwanted and\n",
    "potentially harmful emails.\n",
    "\n",
    "**Q4. Can the Nave Bayes classifier be used on continuous numeric data?\n",
    "If so, how can you go about doing it?**\n",
    "\n",
    "Yes, the Naive Bayes classifier can be used on continuous numeric data.\n",
    "However, it requires an additional step to handle continuous variables\n",
    "properly. There are two common approaches to handle continuous data in\n",
    "Naive Bayes classification:\n",
    "\n",
    "**1. Discretization:** One way to handle continuous variables is to\n",
    "discretize them into categorical or ordinal values. This involves\n",
    "dividing the range of the continuous variable into intervals or bins and\n",
    "converting the values into discrete labels representing the intervals.\n",
    "This allows you to treat the continuous variable as a categorical\n",
    "feature. The choice of binning technique and the number of bins can\n",
    "impact the performance of the classifier.\n",
    "\n",
    "**2. Probability distributions:** Another approach is to model the\n",
    "continuous variables using probability distributions. Instead of\n",
    "discretizing the data, you estimate the parameters of the probability\n",
    "distribution that best fits the data. Commonly used distributions\n",
    "include Gaussian (normal) distribution, multinomial distribution, or\n",
    "other appropriate distributions depending on the nature of the data.\n",
    "Then, you calculate the likelihood of observing a particular value given\n",
    "the class label using the estimated distribution parameters.\n",
    "\n",
    "**Here's a step-by-step process for using the Naive Bayes classifier\n",
    "with continuous numeric data:**\n",
    "\n",
    "**1. Data preprocessing:** Ensure that the continuous numeric features\n",
    "are properly prepared and formatted for analysis. This may involve\n",
    "handling missing values, normalizing or standardizing the data, and\n",
    "checking for any skewness or outliers.\n",
    "\n",
    "**2. Choose a method:** Decide on the approach you want to use to handle\n",
    "the continuous variables: either discretization or modeling them with\n",
    "probability distributions.\n",
    "\n",
    "**3. Discretization:** If you choose discretization, select an\n",
    "appropriate binning technique and divide the range of each continuous\n",
    "variable into intervals or bins. Assign labels to the intervals and\n",
    "convert the continuous data into categorical or ordinal values.\n",
    "\n",
    "**4. Probability distributions:** If you choose to model the continuous\n",
    "variables, estimate the parameters of the probability distribution that\n",
    "best fits the data. For example, you can estimate the mean and standard\n",
    "deviation for a Gaussian distribution. Calculate the likelihood of\n",
    "observing a value given the class label using the estimated distribution\n",
    "parameters.\n",
    "\n",
    "**5. Training:** Apply the Naive Bayes classifier algorithm using the\n",
    "modified or modeled continuous features along with any categorical\n",
    "features. Estimate the prior probabilities and calculate the conditional\n",
    "probabilities using the chosen method for continuous variables.\n",
    "\n",
    "**6. Classification:** Given a new instance with continuous features,\n",
    "apply Bayes' theorem to calculate the posterior probability of each\n",
    "class label. Use the likelihoods derived from either the discretized\n",
    "intervals or the estimated probability distributions. Classify the\n",
    "instance based on the highest posterior probability.\n",
    "\n",
    "It's important to note that the choice between discretization and\n",
    "modeling with probability distributions depends on the nature of the\n",
    "data, the available information, and the specific problem at hand. Both\n",
    "approaches have their advantages and limitations, and the selection\n",
    "should be made based on the characteristics of the dataset and the goals\n",
    "of the classification task.\n",
    "\n",
    "**Q5. What are Bayesian Belief Networks, and how do they work? What are\n",
    "their applications? Are they capable of resolving a wide range of\n",
    "issues?**\n",
    "\n",
    "Bayesian Belief Networks (BBNs), also known as Bayesian Networks or\n",
    "Probabilistic Graphical Models, are probabilistic graphical models that\n",
    "represent and reason about uncertain knowledge using probability theory\n",
    "and graph theory. BBNs provide a graphical and intuitive way to model\n",
    "complex systems by capturing the relationships between variables and\n",
    "their dependencies.\n",
    "\n",
    "**Here's how BBNs work:**\n",
    "\n",
    "**1. Graphical structure:** BBNs consist of two main components: a\n",
    "directed acyclic graph (DAG) and conditional probability tables (CPTs).\n",
    "The DAG represents the variables as nodes, and the directed edges\n",
    "between the nodes represent the dependencies or causal relationships\n",
    "between variables.\n",
    "\n",
    "**2. Nodes and edges:** Each node in the graph represents a random\n",
    "variable, and the edges indicate the probabilistic dependencies between\n",
    "variables. The direction of the edges signifies the direction of\n",
    "influence or causality.\n",
    "\n",
    "**3. Conditional probability tables:** Each node has an associated CPT\n",
    "that quantifies the conditional probabilities of the node given its\n",
    "parents (nodes that directly influence it). The CPT specifies the\n",
    "probabilities of different states or values of the node based on the\n",
    "states or values of its parents.\n",
    "\n",
    "**4. Inference:** BBNs allow for efficient probabilistic inference.\n",
    "Given observed evidence (values of certain variables), BBNs can\n",
    "calculate the probabilities or distributions of unobserved variables\n",
    "using Bayes' theorem and the graphical structure of the network.\n",
    "Inference in BBNs involves updating beliefs and propagating\n",
    "probabilities through the graph to obtain posterior probabilities.\n",
    "\n",
    "**BBNs have a wide range of applications across various domains,\n",
    "including:**\n",
    "\n",
    "**1. Decision support systems:** BBNs can assist in decision-making\n",
    "under uncertainty by incorporating probabilistic reasoning and capturing\n",
    "the complex dependencies between variables.\n",
    "\n",
    "**2. Risk assessment:** BBNs can be used to model and analyze risks in\n",
    "fields such as finance, insurance, healthcare, and engineering. They\n",
    "help in assessing the likelihood and impact of different risks and aid\n",
    "in decision-making for risk mitigation.\n",
    "\n",
    "**3. Diagnosis and prediction:** BBNs are useful for medical diagnosis,\n",
    "fault diagnosis, and predictive modeling. By incorporating prior\n",
    "knowledge and observed evidence, BBNs can infer the likelihood of\n",
    "certain diseases, faults, or events based on the symptoms or observed\n",
    "data.\n",
    "\n",
    "**4. Robotics and autonomous systems:** BBNs can be employed in robotics\n",
    "and autonomous systems to model the environment, make decisions, and\n",
    "plan actions by reasoning about uncertain sensor measurements and\n",
    "environmental states.\n",
    "\n",
    "**Q6. Passengers are checked in an airport screening system to see if\n",
    "there is an intruder. Let I be the random variable that indicates\n",
    "whether someone is an intruder I = 1) or not I = 0), and A be the\n",
    "variable that indicates alarm I = 0). If an intruder is detected with\n",
    "probability P(A = 1\\|I = 1) = 0.98 and a non-intruder is detected with\n",
    "probability P(A = 1\\|I = 0) = 0.001, an alarm will be triggered,\n",
    "implying the error factor. The likelihood of an intruder in the\n",
    "passenger population is P(I = 1) = 0.00001. What are the chances that an\n",
    "alarm would be triggered when an individual is actually an intruder?**\n",
    "\n",
    "To determine the chances that an alarm would be triggered when an\n",
    "individual is actually an intruder, we need to calculate the conditional\n",
    "probability P(I = 1\\|A = 1), which represents the probability of an\n",
    "individual being an intruder given that an alarm is triggered.\n",
    "\n",
    "**According to Bayes' theorem, we can calculate this probability using\n",
    "the following formula:**\n",
    "\n",
    "P(I = 1\\|A = 1) = (P(A = 1\\|I = 1) \\* P(I = 1)) / P(A = 1)\n",
    "\n",
    "**Let's substitute the given values into the formula:**\n",
    "\n",
    "P(A = 1\\|I = 1) = 0.98 (probability of an alarm given an intruder)\n",
    "\n",
    "P(I = 1) = 0.00001 (likelihood of an intruder in the passenger\n",
    "population)\n",
    "\n",
    "Now, we need to calculate P(A = 1), which represents the probability of\n",
    "an alarm being triggered, regardless of whether an individual is an\n",
    "intruder or not.\n",
    "\n",
    "P(A = 1) = P(A = 1\\|I = 1) \\* P(I = 1) + P(A = 1\\|I = 0) \\* P(I = 0)\n",
    "\n",
    "Given that P(A = 1\\|I = 0) = 0.001 (probability of an alarm given a\n",
    "non-intruder) and P(I = 0) = 1 - P(I = 1), we can calculate P(A = 1) as\n",
    "follows:\n",
    "\n",
    "P(A = 1) = (0.98 \\* 0.00001) + (0.001 \\* (1 - 0.00001))\n",
    "\n",
    "Now, we can substitute the calculated values into the Bayes' theorem\n",
    "formula to find the conditional probability:\n",
    "\n",
    "P(I = 1\\|A = 1) = (0.98 \\* 0.00001) / \\[(0.98 \\* 0.00001) + (0.001 \\*\n",
    "(1 - 0.00001))\\]\n",
    "\n",
    "Simplifying the equation will give us the final result:\n",
    "\n",
    "P(I = 1\\|A = 1) = 0.0098\n",
    "\n",
    "**Therefore,** the chances that an alarm would be triggered when an\n",
    "individual is actually an intruder are 0.0098 or approximately 0.98%.\n",
    "\n",
    "**Q7. An antibiotic resistance test (random variable T) has 1% false\n",
    "positives (i.e., 1% of those who are not immune to an antibiotic display\n",
    "a positive result in the test) and 5% false negatives (i.e., 1% of those\n",
    "who are not resistant to an antibiotic show a positive result in the\n",
    "test) (i.e. 5 percent of those actually resistant to an antibiotic test\n",
    "negative). Assume that 2% of those who were screened were\n",
    "antibiotic-resistant. Calculate the likelihood that a person who tests\n",
    "positive is actually immune (random variable D).**\n",
    "\n",
    "To calculate the likelihood that a person who tests positive is actually\n",
    "immune (antibiotic-resistant), we need to determine the conditional\n",
    "probability P(D = 1\\|T = 1), which represents the probability of being\n",
    "immune given a positive test result.\n",
    "\n",
    "**According to Bayes' theorem, we can calculate this probability using\n",
    "the following formula:**\n",
    "\n",
    "P(D = 1\\|T = 1) = (P(T = 1\\|D = 1) \\* P(D = 1)) / P(T = 1)\n",
    "\n",
    "**Let's substitute the given values into the formula:**\n",
    "\n",
    "P(T = 1\\|D = 1) = 1 - 0.05 = 0.95 (probability of a positive test given\n",
    "immune)\n",
    "\n",
    "P(D = 1) = 0.02 (likelihood of being immune)\n",
    "\n",
    "P(T = 1) = P(T = 1\\|D = 1) \\* P(D = 1) + P(T = 1\\|D = 0) \\* P(D = 0)\n",
    "\n",
    "**Given that P(T = 1\\|D = 0) = 0.01 (probability of a positive test\n",
    "given not immune) and P(D = 0) = 1 - P(D = 1), we can calculate P(T = 1)\n",
    "as follows:**\n",
    "\n",
    "P(T = 1) = (0.95 \\* 0.02) + (0.01 \\* (1 - 0.02))\n",
    "\n",
    "**Now, we can substitute the calculated values into the Bayes' theorem\n",
    "formula to find the conditional probability:**\n",
    "\n",
    "P(D = 1\\|T = 1) = (0.95 \\* 0.02) / \\[(0.95 \\* 0.02) + (0.01 \\* (1 -\n",
    "0.02))\\]\n",
    "\n",
    "**Simplifying the equation will give us the final result:**\n",
    "\n",
    "P(D = 1\\|T = 1) ≈ 0.655\n",
    "\n",
    "Therefore, the likelihood that a person who tests positive is actually\n",
    "immune (antibiotic-resistant) is approximately 0.655 or 65.5%.\n",
    "\n",
    "**Q8. In order to prepare for the test, a student knows that there will\n",
    "be one question in the exam that is either form A, B, or C. The chances\n",
    "of getting an A, B, or C on the exam are 30 percent, 20%, and 50\n",
    "percent, respectively. During the planning, the student solved 9 of 10\n",
    "type A problems, 2 of 10 type B problems, and 6 of 10 type C problems.**\n",
    "\n",
    "**1. What is the likelihood that the student can solve the exam\n",
    "problem?**\n",
    "\n",
    "> **2. Given the student's solution, what is the likelihood that the\n",
    "> problem was of form A?**\n",
    "\n",
    "**1. To calculate the likelihood that the student can solve the exam\n",
    "problem, we need to consider the probability of the student being able\n",
    "to solve each type of problem (A, B, and C) and the probabilities of\n",
    "encountering each type of problem.**\n",
    "\n",
    "**Let's denote the events as follows:**\n",
    "\n",
    "-   S: The student can solve the exam problem.\n",
    "\n",
    "-   A: The problem is of type A.\n",
    "\n",
    "-   B: The problem is of type B.\n",
    "\n",
    "-   C: The problem is of type C.\n",
    "\n",
    "**We are given the following probabilities:**\n",
    "\n",
    "P(A) = 0.30 (probability of a problem being of type A)\n",
    "\n",
    "P(B) = 0.20 (probability of a problem being of type B)\n",
    "\n",
    "P(C) = 0.50 (probability of a problem being of type C)\n",
    "\n",
    "**We also have the following conditional probabilities based on the\n",
    "student's preparation:**\n",
    "\n",
    "P(S\\|A) = 9/10 (probability of solving a type A problem)\n",
    "\n",
    "P(S\\|B) = 2/10 (probability of solving a type B problem)\n",
    "\n",
    "P(S\\|C) = 6/10 (probability of solving a type C problem)\n",
    "\n",
    "**Using Bayes' theorem, we can calculate the likelihood that the student\n",
    "can solve the exam problem (P(S)):**\n",
    "\n",
    "P(S) = P(S\\|A) \\* P(A) + P(S\\|B) \\* P(B) + P(S\\|C) \\* P(C)\n",
    "\n",
    "**Substituting the given values:**\n",
    "\n",
    "P(S) = (9/10) \\* (0.30) + (2/10) \\* (0.20) + (6/10) \\* (0.50)\n",
    "\n",
    "**Simplifying the equation will give us the final result:**\n",
    "\n",
    "P(S) = 0.27 + 0.04 + 0.30 = 0.61\n",
    "\n",
    "**Therefore,** the likelihood that the student can solve the exam\n",
    "problem is 0.61 or 61%.\n",
    "\n",
    "**2. To find the likelihood that the problem was of form A given the\n",
    "student's solution (P(A\\|S)), we can use Bayes' theorem again:**\n",
    "\n",
    "P(A\\|S) = (P(S\\|A) \\* P(A)) / P(S)\n",
    "\n",
    "**Using the values we already know:**\n",
    "\n",
    "P(A\\|S) = (9/10) \\* (0.30) / 0.61\n",
    "\n",
    "**Simplifying the equation will give us the final result:**\n",
    "\n",
    "P(A\\|S) = 0.45 / 0.61 ≈ 0.74\n",
    "\n",
    "**Therefore, the likelihood that the problem was of form A given the\n",
    "student's solution is approximately 0.74 or 74%.**\n",
    "\n",
    "**Q9. A bank installs a CCTV system to track and photograph incoming\n",
    "customers. Despite the constant influx of customers, we divide the\n",
    "timeline into 5-minute bins. There may be a customer coming into the\n",
    "bank with a 5% chance in each 5-minute time period, or there may be no\n",
    "customer (again, for simplicity, we assume that either there is 1\n",
    "customer or none, not the case of multiple customers). If there is a\n",
    "client, the CCTV will detect them with a 99 percent probability. If\n",
    "there is no customer, the camera can take a false photograph with a 10%\n",
    "chance of detecting movement from other objects.**\n",
    "\n",
    "**1. How many customers come into the bank on a daily basis (10\n",
    "hours)?**\n",
    "\n",
    "> **2. On a daily basis, how many fake photographs (photographs taken\n",
    "> when there is no customer) and how many missed photographs\n",
    "> (photographs taken when there is a customer) are there?**\n",
    "\n",
    "**3. Explain likelihood that there is a customer if there is a\n",
    "photograph?**\n",
    "\n",
    "**1. To calculate the expected number of customers coming into the bank\n",
    "on a daily basis, we need to consider the probability of a customer\n",
    "arriving in each 5-minute time period and the total number of 5-minute\n",
    "time periods in 10 hours (assuming each time period is independent).**\n",
    "\n",
    "The probability of a customer arriving in each 5-minute time period is\n",
    "0.05 (5% chance). The total number of 5-minute time periods in 10 hours\n",
    "is (10 hours \\* 60 minutes) / 5 minutes = 120 time periods.\n",
    "\n",
    "**Therefore,** the expected number of customers coming into the bank on\n",
    "a daily basis is:\n",
    "\n",
    "Expected number = Probability of arrival \\* Total number of time periods\n",
    "= 0.05 \\* 120 = 6 customers.\n",
    "\n",
    "Hence, approximately 6 customers come into the bank on a daily basis.\n",
    "\n",
    "**2. To calculate the number of fake photographs and missed photographs\n",
    "on a daily basis, we need to consider the probabilities of false\n",
    "detection and missed detection in each 5-minute time period.**\n",
    "\n",
    "The probability of a false photograph (false positive) when there is no\n",
    "customer is 0.10 (10% chance), and the probability of missing a\n",
    "photograph (false negative) when there is a customer is 1 - 0.99 = 0.01\n",
    "(1% chance).\n",
    "\n",
    "**Let's calculate the number of fake photographs and missed photographs\n",
    "in the 10-hour period:**\n",
    "\n",
    "Number of fake photographs = Probability of false photograph \\* Total\n",
    "number of time periods\n",
    "\n",
    "Number of fake photographs = 0.10 \\* 120 = 12 photographs\n",
    "\n",
    "Number of missed photographs = Probability of missed photograph \\* Total\n",
    "number of customers\n",
    "\n",
    "Number of missed photographs = 0.01 \\* 6 = 0.06 photographs (rounded to\n",
    "the nearest whole number)\n",
    "\n",
    "Therefore, on a daily basis, there are approximately 12 fake photographs\n",
    "and less than 1 missed photograph.\n",
    "\n",
    "**3. The likelihood that there is a customer given a photograph\n",
    "(P(Customer\\|Photograph)) can be calculated using Bayes' theorem. Let's\n",
    "denote the events as follows:**\n",
    "\n",
    "C: There is a customer.\n",
    "\n",
    "P: A photograph is taken.\n",
    "\n",
    "**We need to calculate P(C\\|P), the probability of a customer being\n",
    "present given that a photograph is taken.**\n",
    "\n",
    "According to Bayes' theorem:\n",
    "\n",
    "P(C\\|P) = (P(P\\|C) \\* P(C)) / P(P)\n",
    "\n",
    "P(P\\|C) is the probability of a photograph being taken when a customer\n",
    "is present, which is 0.99 (99% detection rate).\n",
    "\n",
    "P(C) is the probability of a customer being present, which is 0.05 (5%\n",
    "chance of a customer in each time period).\n",
    "\n",
    "P(P) is the probability of a photograph being taken, which can be\n",
    "calculated as follows:\n",
    "\n",
    "P(P) = P(P\\|C) \\* P(C) + P(P\\|\\~C) \\* P(\\~C)\n",
    "\n",
    "P(P\\|\\~C) is the probability of a photograph being taken when there is\n",
    "no customer (false positive), which is 0.10 (10% chance).\n",
    "\n",
    "P(\\~C) is the probability of no customer being present, which is 1 -\n",
    "P(C) = 1 - 0.05 = 0.95.\n",
    "\n",
    "Substituting the values into the equation, we can calculate P(P):\n",
    "\n",
    "P(P) = (0.99 \\* 0.05) + (0.10 \\* 0.95) = 0.0495 + 0.095 = 0.1445\n",
    "\n",
    "Now, we can calculate P(C\\|P) using Bayes' theorem:\n",
    "\n",
    "P(C\\|P) = (0.99 \\* 0.05) / 0.1445 ≈ 0.3427\n",
    "\n",
    "**Therefore,** the likelihood that there is a customer\n",
    "\n",
    "if there is a photograph is approximately 0.3427 or 34.27%.\n",
    "\n",
    "**Q10. Create the conditional probability table associated with the node\n",
    "Won Toss in the Bayesian Belief network to represent the conditional\n",
    "independence assumptions of the Nave Bayes classifier for the match\n",
    "winning prediction problem in Section 6.4.4.**\n",
    "\n",
    "To create the conditional probability table (CPT) for the \"Won Toss\"\n",
    "node in the Naive Bayes classifier for the match winning prediction\n",
    "problem, we need to specify the conditional probabilities of the \"Won\n",
    "Toss\" variable given the class variable (Match Outcome) and other\n",
    "predictor variables (such as Weather, Pitch Conditions, and Home Ground\n",
    "Advantage).\n",
    "\n",
    "**Let's assume the following values for the variables:**\n",
    "\n",
    "-   Match Outcome (Class variable): {Win, Lose}\n",
    "\n",
    "-   Weather: {Sunny, Cloudy, Rainy}\n",
    "\n",
    "-   Pitch Conditions: {Dry, Damp, Wet}\n",
    "\n",
    "-   Home Ground Advantage: {Yes, No}\n",
    "\n",
    "Now, we will create the conditional probability table for the \"Won Toss\"\n",
    "variable based on the conditional independence assumptions of the Naive\n",
    "Bayes classifier:\n",
    "\n",
    "\\| Match Outcome \\| Weather \\| Pitch Conditions \\| Home Ground Advantage\n",
    "\\| P(Won Toss = Yes \\\\\\| X) \\| P(Won Toss = No \\\\\\| X) \\|\n",
    "\n",
    "\\| ------------- \\| ------- \\| ---------------- \\| ---------------------\n",
    "\\| --------------------- \\| -------------------- \\|\n",
    "\n",
    "\\| Win \\| Sunny \\| Dry \\| Yes \\| p1 \\| 1 - p1 \\|\n",
    "\n",
    "\\| Win \\| Sunny \\| Dry \\| No \\| p2 \\| 1 - p2 \\|\n",
    "\n",
    "\\| Win \\| Sunny \\| Damp \\| Yes \\| p3 \\| 1 - p3 \\|\n",
    "\n",
    "\\| Win \\| Sunny \\| Damp \\| No \\| p4 \\| 1 - p4 \\|\n",
    "\n",
    "\\| Win \\| Sunny \\| Wet \\| Yes \\| p5 \\| 1 - p5 \\|\n",
    "\n",
    "\\| Win \\| Sunny \\| Wet \\| No \\| p6 \\| 1 - p6 \\|\n",
    "\n",
    "\\| Win \\| Cloudy \\| Dry \\| Yes \\| p7 \\| 1 - p7 \\|\n",
    "\n",
    "\\| Win \\| Cloudy \\| Dry \\| No \\| p8 \\| 1 - p8 \\|\n",
    "\n",
    "\\| Win \\| Cloudy \\| Damp \\| Yes \\| p9 \\| 1 - p9 \\|\n",
    "\n",
    "\\| Win \\| Cloudy \\| Damp \\| No \\| p10 \\| 1 - p10 \\|\n",
    "\n",
    "\\| Win \\| Cloudy \\| Wet \\| Yes \\| p11 \\| 1 - p11 \\|\n",
    "\n",
    "\\| Win \\| Cloudy \\| Wet \\| No \\| p12 \\| 1 - p12 \\|\n",
    "\n",
    "\\| Win \\| Rainy \\| Dry \\| Yes \\| p13 \\| 1 - p13 \\|\n",
    "\n",
    "\\| Win \\| Rainy \\| Dry \\| No \\| p14 \\| 1 - p14 \\|\n",
    "\n",
    "\\| Win \\| Rainy \\| Damp \\| Yes \\| p15 \\| 1 - p15 \\|\n",
    "\n",
    "\\| Win \\| Rainy \\| Damp \\| No \\| p16 \\| 1 - p16 \\|\n",
    "\n",
    "\\| Win \\| Rainy \\| Wet \\| Yes \\| p17 \\| 1 - p17 \\|\n",
    "\n",
    "\\| Win \\| Rainy \\| Wet \\| No \\| p18 \\| 1 - p18 \\|\n",
    "\n",
    "\\| Lose \\| Sunny \\| Dry \\| Yes \\| p19 \\| 1 - p19 \\|\n",
    "\n",
    "\\| Lose \\| Sunny \\| Dry \\| No \\| p20 \\| 1 - p20 \\|\n",
    "\n",
    "\\| Lose \\| Sunny \\| Damp \\| Yes \\| p21 \\| 1 - p21 \\|\n",
    "\n",
    "\\| Lose \\| Sunny \\| Damp \\| No \\| p22 \\| 1 - p22 \\|\n",
    "\n",
    "\\| Lose \\| Sunny \\| Wet"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
